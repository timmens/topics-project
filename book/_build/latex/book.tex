%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}




\title{Topics in Econometrics and Statistics}
\date{Sep 06, 2020}
\release{}
\author{Tim Mensinger}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}


\sphinxstyleemphasis{\sphinxstylestrong{Topics in Econometrics and Statistics, University of Bonn, 2020 \textendash{} Prof. Joachim Freyberger}}

In this document I present my submission to the project for the topics class in
econometrics and statistics, due by 13th September 2020.


\chapter{Problem Description}
\label{\detokenize{intro:problem-description}}
For the project we have been given a simulated data set and a real data set. For each
data set some of the observed outcomes are held back. The task is to build a model for
each data set on the training set and submit the predictions on the test set.

The following part of this document is structured as follows. At the end of this
section I present a link to my predictions for the respective data sets. In the next
chapter I present the model for the simulated data set. Aftwards I introduce my model
for the stock data set.


\chapter{Data Format}
\label{\detokenize{intro:data-format}}
Please note that I changed the file format from an RData file to a \sphinxhref{https://parquet.apache.org/}{parquet} file, as this is not dependent on the specific programming language. If you want to reproduce my results using my code (see below) you need to transform the RData files to parquet files. This can easily be done, for example, with the \sphinxhref{https://spark.apache.org/docs/1.6.2/api/R/write.parquet.html}{SparkR} package for R. For the project to run I expect the two data files to be located in the folder \sphinxcode{\sphinxupquote{data}} with names \sphinxcode{\sphinxupquote{simulated\_data.parquet}} and \sphinxcode{\sphinxupquote{stock\_data.parquet}}, respectively.


\chapter{Code}
\label{\detokenize{intro:code}}
In this project I have to sets of code bases. Nearly all of the code presented in the following notebooks is embedded in the notebooks themselves. For the final predictions however, I use Python scripts which are stored \sphinxhref{https://github.com/timmens/topics-project/}{here}. The script \sphinxhref{https://github.com/timmens/topics-project/tree/main/codes/build\_project.py}{build\_project.py} runs all scripts that are necessary to produce the predictions. If you want to rerun these codes on your computer open your favorite terminal emulator and run the following line by line (I assume you have at least \sphinxhref{https://docs.conda.io/en/latest/miniconda.html}{miniconda} already installed on your system, otherwise read the note below.)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{}} git clone https://github.com/timmens/topics\PYGZhy{}project.git
\PYG{g+gp}{\PYGZdl{}} conda env create \PYGZhy{}f environment.yml
\PYG{g+gp}{\PYGZdl{}} conda activate topics\PYGZhy{}project
\PYG{g+gp}{\PYGZdl{}} \PYG{n+nb}{cd} codes
\PYG{g+gp}{\PYGZdl{}} python build\PYGZus{}project.py
\end{sphinxVerbatim}

\sphinxstyleemphasis{\sphinxstylestrong{Note.}}
It is not necessary to use conda here as long as all the packages that I use are available to the Python interpreter. Conda just provides a very easy way to create a sandbox environment in which all packages will be available without messing with the system.


\chapter{Predictions}
\label{\detokenize{intro:predictions}}
Predictions for the respective data sets are stored on github and can be downloaded here
\begin{itemize}
\item {} 
Simulated data: \sphinxhref{https://rawcdn.githack.com/timmens/topics-project/4045ae9fac293ec2aff62d4d9e6f3f8989f768cb/bld/predictions\_simulated.csv}{(click here to download)}

\item {} 
Stock data: \sphinxhref{https://rawcdn.githack.com/timmens/topics-project/4045ae9fac293ec2aff62d4d9e6f3f8989f768cb/bld/predictions\_stock.csv}{(click here to download)}

\end{itemize}


\section{Simulated Data}
\label{\detokenize{simulated:simulated-data}}\label{\detokenize{simulated::doc}}
In the following sections I present my investigation of the simulated data set.
I start with a quick exploration of the data set.
I then show my first endeavors to analyze the data using reverse engineering.
And finally I show my top four models which I compare on a validation set.


\subsection{Data Description}
\label{\detokenize{simulated_intro:data-description}}\label{\detokenize{simulated_intro::doc}}
Let us first look at a few observations of the data set.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{n}{ROOT} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{simulated\PYGZus{}data.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{df}\PYG{o}{.}\PYG{n}{iloc}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
          Y        X1        X2        X3        X4        X5        X6  \PYGZbs{}
0  2.125298  0.711338  0.683167  0.493706  0.317948  0.374013  0.600761   
1 \PYGZhy{}1.102707  0.666355  0.422247  0.366055  0.390193  0.499254  0.602870   
2 \PYGZhy{}2.847834  0.065469  0.307784  0.225924  0.233217  0.528559  0.468785   
3 \PYGZhy{}0.386088  0.715237  0.487894  0.716503  0.595477  0.619713  0.761047   
4  2.518977  0.144925  0.368206  0.335244  0.426445  0.564264  0.478321   

         X7        X8        X9  
0  0.630743  0.726537  0.632634  
1  0.379105  0.547651  0.507543  
2  0.787321  0.831501  0.957693  
3  0.879549  0.925856  0.979782  
4  0.466601  0.426546  0.591990  
\end{sphinxVerbatim}

The data set consists of 100\_000 observations of a single continuous outcome and 100 continuous features which have been transformed to a uniform distribution. Of the 100\_000 observations 20\_000 are designed for the testing step and are marked by a \sphinxcode{\sphinxupquote{NaN}} in the outcome column.


\subsubsection{Train / Validation Split}
\label{\detokenize{simulated_intro:train-validation-split}}
I (randomly) split the remaining 80\_000 \sphinxstyleemphasis{labelled} data points into 65\_000 (81.25\%) training points and 15\_000 validation points. As is standard in the literature I will train all of my models on the training points and compare the performance on the validation points. The \sphinxstyleemphasis{best} model overall is then trained on all 80\_000 points and used to predict the outcomes on the test set.
This splitting procedure is implemented in the script \sphinxhref{https://github.com/timmens/topics-project/blob/main/codes/train\_test\_split.py}{train\_test\_split.py}.


\subsubsection{Next Up}
\label{\detokenize{simulated_intro:next-up}}
In the next section on “reverse engineering” I will present a few techniques I used to learn more about the data at hand. If you only care about the final model I considered then feel free to skip this section.


\subsection{Reverse Engineering}
\label{\detokenize{simulated_reverse_engineering:reverse-engineering}}\label{\detokenize{simulated_reverse_engineering::doc}}
In the following I will present a few things I learned about the data through “\sphinxstyleemphasis{reverse data engineering}”. The main idea was to learn enough of the underlying process to be able to propose simple models from which I could simulate data, which in turn I could compare to the observed data to test the fit. Unfortunately however, in the end I did not learn enough to beat my final black\sphinxhyphen{}box algorithms in terms of prediction on the validation set, which is why I did not pursue this path any further. Nevertheless the insights made here can still be interesting. If, however, you wish to jump right to the final model please skip this section.


\subsubsection{Preliminaries}
\label{\detokenize{simulated_reverse_engineering:preliminaries}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{import} \PYG{n+nn}{importlib}
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{seaborn} \PYG{k}{as} \PYG{n+nn}{sns}

\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LinearRegression}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LassoCV}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{RidgeCV}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{lars\PYGZus{}path}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}selection} \PYG{k+kn}{import} \PYG{n}{RFECV}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{PolynomialFeatures}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{gaussian\PYGZus{}process}\PYG{n+nn}{.}\PYG{n+nn}{kernels} \PYG{k+kn}{import} \PYG{n}{Matern}

\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{stats} \PYG{k+kn}{import} \PYG{n}{multivariate\PYGZus{}normal}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{stats} \PYG{k+kn}{import} \PYG{n}{norm}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{stats} \PYG{k+kn}{import} \PYG{n}{t}

\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Video}

\PYG{n}{ROOT} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}

\PYG{c+c1}{\PYGZsh{} load module using path (I am to lazy to make a python package out of this project..)}
\PYG{n}{spec} \PYG{o}{=} \PYG{n}{importlib}\PYG{o}{.}\PYG{n}{util}\PYG{o}{.}\PYG{n}{spec\PYGZus{}from\PYGZus{}file\PYGZus{}location}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{shared.py}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{shared.py}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{shared} \PYG{o}{=} \PYG{n}{spec}\PYG{o}{.}\PYG{n}{loader}\PYG{o}{.}\PYG{n}{load\PYGZus{}module}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{rcParams}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{figure.figsize}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}
\PYG{n}{colors} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZsh{}DAA520}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZsh{}4169E1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZsh{}228B22}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZsh{}A52A2A}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{sns}\PYG{o}{.}\PYG{n}{set\PYGZus{}context}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{notebook}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{font\PYGZus{}scale}\PYG{o}{=}\PYG{l+m+mf}{1.5}\PYG{p}{,} \PYG{n}{rc}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lines.linewidth}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{l+m+mf}{2.5}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{sns}\PYG{o}{.}\PYG{n}{set\PYGZus{}palette}\PYG{p}{(}\PYG{n}{sns}\PYG{o}{.}\PYG{n}{color\PYGZus{}palette}\PYG{p}{(}\PYG{n}{colors}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{sns}\PYG{o}{.}\PYG{n}{set\PYGZus{}style}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{whitegrid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bld}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}simulated.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{X} \PYG{o}{=} \PYG{n}{df}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{df}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\end{sphinxVerbatim}


\subsubsection{Features}
\label{\detokenize{simulated_reverse_engineering:features}}
By construction our data set consists of \(K=100\) features which are transformed to be uniformly distributed on \([0, 1]\).
Unfortunately this is all the prior knowledge we have.

Looking at the correlation between features we notice that the correlation structure looks very similar to the covariance structure of a \sphinxhref{https://en.wikipedia.org/wiki/Mat\%C3\%A9rn\_covariance\_function}{Matérn covariance function}. This can be seen especially well when considering a correlation heatmap of the observed features.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{shared}\PYG{o}{.}\PYG{n}{correlation\PYGZus{}heatmap}\PYG{p}{(}\PYG{n}{df}\PYG{o}{=}\PYG{n}{X}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_5_0}.png}

For a comparison, consider a (true) Matérn covariance heatmap.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{matern\PYGZus{}kernel} \PYG{o}{=} \PYG{n}{Matern}\PYG{p}{(}\PYG{n}{length\PYGZus{}scale}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{nu}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}

\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{Sigma} \PYG{o}{=} \PYG{n}{matern\PYGZus{}kernel}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}

\PYG{n}{shared}\PYG{o}{.}\PYG{n}{correlation\PYGZus{}heatmap}\PYG{p}{(}\PYG{n}{corr}\PYG{o}{=}\PYG{n}{Sigma}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_7_0}.png}


\paragraph{Simulation?}
\label{\detokenize{simulated_reverse_engineering:simulation}}
Given the hypothesis that the features were simulated using the Matern covariance matrix, can we actually formulate an algroithm for this simulation step?

Let \(Z\) denote a \(K\) dimensional random vector.
If we assume that the individual entries \(Z_k\) have unit standard deviation, then \(\text{corr}(Z) = \text{cov}(Z)\).

Hence, we can simulate features with the structure from above using the following simple algorithm. For this let \(\Sigma\) denote the above Matérn covariance matrix (parameterized with \(\ell = 0.1\) and \(\nu\) = 0.5).

\sphinxstylestrong{Algorithm}:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Draw samples \(Z^{(i)}\) from \(\mathcal{N}(0, \Sigma)\) for \(i=1,\dots,n\)

\item {} 
Transform each sample to a uniform by \(X^{(i)}_j = \Phi(Z^{(i)}_j)\) for each \(i=1,\dots,n ; j=1,\dots,K\)

\end{enumerate}

where \(\Phi\) denotes the standard normal cumulative distribution function.

To check wether this works let us simulate a small data set in this fashion. We need to check that the empirical correlation matrix resembles the ones from above, and that the marginal distributions are approximately uniform.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{n} \PYG{o}{=} \PYG{l+m+mi}{25\PYGZus{}000}
\PYG{n}{mvnormal} \PYG{o}{=} \PYG{n}{multivariate\PYGZus{}normal}\PYG{p}{(}\PYG{n}{cov}\PYG{o}{=}\PYG{n}{Sigma}\PYG{p}{)}
\PYG{n}{Z} \PYG{o}{=} \PYG{n}{mvnormal}\PYG{o}{.}\PYG{n}{rvs}\PYG{p}{(}\PYG{n}{n}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{n}{columns} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{k}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{for} \PYG{n}{k} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{101}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{XX} \PYG{o}{=} \PYG{n}{norm}\PYG{o}{.}\PYG{n}{cdf}\PYG{p}{(}\PYG{n}{Z}\PYG{p}{)}
\PYG{n}{XX} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{,} \PYG{n}{columns}\PYG{o}{=}\PYG{n}{columns}\PYG{p}{)}

\PYG{n}{shared}\PYG{o}{.}\PYG{n}{correlation\PYGZus{}heatmap}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_9_0}.png}

And checking that each column is really uniform distributed by considering a histogram (here we select a few columns randomly since looking at all 100 is too annoying..)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{for} \PYG{n}{col} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X12}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X37}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{:}
    \PYG{n}{sns}\PYG{o}{.}\PYG{n}{distplot}\PYG{p}{(}
        \PYG{n}{XX}\PYG{p}{[}\PYG{n}{col}\PYG{p}{]}\PYG{p}{,} 
        \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{50}\PYG{p}{,}
        \PYG{n}{norm\PYGZus{}hist}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
        \PYG{n}{kde}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
        \PYG{n}{hist\PYGZus{}kws}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{range}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
    \PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_11_0}.png}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_11_1}.png}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_11_2}.png}


\paragraph{Recap \sphinxhyphen{} Features}
\label{\detokenize{simulated_reverse_engineering:recap-features}}
We have seen that the covariance/correlation structure of the features is very similar to a Matern covariance.
A major component of feature analysis is to check wether one can reduce the dimensionality of the feature set.
As all our features are distributed identically and the correlation structure does not admit any grouping we cannot apply classical techniques such as PCA for sensible dimensionality reduction.
This means if we want to reduce the dimensionality we have to actually find and eliminate the features that are unrelated with the outcome or have a negligible effect.


\subsubsection{Outcomes}
\label{\detokenize{simulated_reverse_engineering:outcomes}}
To learn more about the outcome structure I fit the parameters of a normal and t distribution on the outcomes, plot the outcomes using a histogram and draw the two distributions on top. Visualizing the outcome distribution can be important to check wether one needs to transform the distribution, e.g. in the case of positive data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mle\PYGZus{}tuple\PYGZus{}t} \PYG{o}{=} \PYG{n}{t}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{floc}\PYG{o}{=}\PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{mle\PYGZus{}tuple\PYGZus{}norm} \PYG{o}{=} \PYG{n}{norm}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{t\PYGZus{}distr} \PYG{o}{=} \PYG{n}{t}\PYG{p}{(}\PYG{o}{*}\PYG{n}{mle\PYGZus{}tuple\PYGZus{}t}\PYG{p}{)}
\PYG{n}{norm\PYGZus{}distr} \PYG{o}{=} \PYG{n}{norm}\PYG{p}{(}\PYG{o}{*}\PYG{n}{mle\PYGZus{}tuple\PYGZus{}norm}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{1000}\PYG{p}{)}
\PYG{n}{ax} \PYG{o}{=} \PYG{n}{sns}\PYG{o}{.}\PYG{n}{distplot}\PYG{p}{(}\PYG{n}{y}\PYG{p}{,} \PYG{n}{kde}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{norm\PYGZus{}hist}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{t\PYGZus{}distr}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{2.5}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{goldenrod}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{norm\PYGZus{}distr}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{2.5}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{royalblue}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t\PYGZhy{}distr.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{normal\PYGZhy{}distr.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{prop}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{16}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_15_0}.png}

From the plot we can see that the outcomes are more tightly centered than we would expect from a normal distribution. The fitted t\sphinxhyphen{}distribution fits the outcome distribution better but still not optimal. Nevertheless if we are willing to assume exogeneity and an additive error structure, we would expect from the above plot that the model errors follow a more tightly centered distribution with large tails rather than a normal.

The most important insight from the above plot is that there is no need to transform the outcome for a better model fit, as is the case for constrained or positive data.


\subsubsection{Relationship Between Outcomes and Features}
\label{\detokenize{simulated_reverse_engineering:relationship-between-outcomes-and-features}}
To better understand how the outcomes are affected by the features I consider one dimensional regression plots. That is, for each feature \(X_k\) (\(k=1,\dots,K\)) I consider the plot of \(Y\) vs. \(X_k\).
(Offline I also considered all two dimensional interaction plot but these are too many to be displayed here and they did not provide any useful insights.)

Since \(K\) (=100) plots are quite a few plots I simpy show a video where we iterate through all plots very fast…

The black line seen in the plot denotes the regression line for the model \(Y \sim \beta_0 + \beta_1 X_k + \beta_2 X_k^2 + \beta_3 X_k^3\).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Video}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{figures}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{no\PYGZus{}interaction.mp4}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{embed}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{html\PYGZus{}attributes}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{controls muted}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.Video object\PYGZgt{}
\end{sphinxVerbatim}

It is clear that from these univariate effect plots we cannot read\sphinxhyphen{}off the entire model, nevertheless these plots contain a great amount of information.

Firstly, we see that “the effect of \(X_k\) on \(Y\)” is, in a sense, \sphinxstyleemphasis{continuous} in \(k\).
That makes sense since we already observed that the features follow a Matern style covariance structure which implies that neighboring features (here: neighboring in the sense that the \(k\)’s are close) are heavily correlated.
Hence, we would expect that these neighboring features \sphinxstyleemphasis{look like} they have a similar effect on the outcome.

Secondly, we see that for many \(k\)’s the effect looks negligible.
In the next steps we analyze this structure of the data more closely and try to establish a more quantitative answer to whether some features are irrelevant.

Lastly, before jumping into a quantitative analysis let me provide a guess on how the above data structure could have emerged.
Say we model the outcomes using an additive model and each component is modeled by a 3rd degree polynomial.
We then pick a few features, say 2\sphinxhyphen{}5, and give them non\sphinxhyphen{}zero coefficients.
Since the features were created with the special covariance structure from above we would expect that for all features that are close to features with non\sphinxhyphen{}zero coefficients, the estimated coefficents would also be non\sphinxhyphen{}zero, but shrunk towards zero.


\paragraph{Quantitative Analysis}
\label{\detokenize{simulated_reverse_engineering:quantitative-analysis}}
To get a more quantatitive understanding of which features matter I will
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Fit a regularized linear model (first\sphinxhyphen{}degree, second\sphinxhyphen{}degree) using the Lasso and disregard features with zero\sphinxhyphen{}coefficient

\item {} 
Use a recursive feature elimination with cross\sphinxhyphen{}validation

\item {} 
Fit a third\sphinxhyphen{}degree ridge regression for each feature dimension and compare coefficients

\end{enumerate}

I wont dive too deep into the details of each approach as in the end I decided to pusue a very different route.

Each of the following approaches could have been used to select a small subset of features on which another model could have been fit in a second stage. I did not pursue this strategy in my final model, which is why I do not provide any detailed explainations. Nevertheless the results from below convinced me that the main effects in the data are sparse, which led me to choose hyperparameters in my final machine learning model that perform better under sparsity. This approach also goes well with the “Bet on Sparsity” principle, on which Rob Tibshirani writes:
\begin{quote}

Hastie et al. (2001) coined the informal “Bet on Sparsity” principle. The l1 methods assume that the truth is sparse, in some basis. If the assumption holds true, then the parameters can be efficiently estimated using l1 penalties. If the assumption does not hold—so that the truth is dense—then no method will be able to recover the underlying model without a large amount of data per parameter.
\end{quote}


\subparagraph{The Lasso Approach}
\label{\detokenize{simulated_reverse_engineering:the-lasso-approach}}
To find relevant features we fit a l1 regularized linear model with a) all first\sphinxhyphen{}degree terms and b) all first\sphinxhyphen{}degree, second\sphinxhyphen{}degree and first\sphinxhyphen{}degree\sphinxhyphen{}interaction terms. For case a) I will also plot the Lasso path. I won’t do that for case b) since there will be too many coefficients.

For both approaches I find the \sphinxstyleemphasis{optimal} regularization parameter via 5\sphinxhyphen{}fold cross\sphinxhyphen{}validation on 50 different alphas.

\sphinxstyleemphasis{\sphinxstylestrong{a: first\sphinxhyphen{}degree}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{lasso\PYGZus{}model} \PYG{o}{=} \PYG{n}{LassoCV}\PYG{p}{(}\PYG{n}{eps}\PYG{o}{=}\PYG{l+m+mf}{0.05}\PYG{p}{,} \PYG{n}{n\PYGZus{}alphas}\PYG{o}{=}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{n}{cv}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{lasso\PYGZus{}model} \PYG{o}{=} \PYG{n}{lasso\PYGZus{}model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}

\PYG{n}{relevant} \PYG{o}{=} \PYG{n}{X}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{[}\PYG{n}{lasso\PYGZus{}model}\PYG{o}{.}\PYG{n}{coef\PYGZus{}} \PYG{o}{!=} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}list}\PYG{p}{(}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Relevant features chosen via Lasso:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{relevant}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Relevant features chosen via Lasso: [\PYGZsq{}X3\PYGZsq{}, \PYGZsq{}X12\PYGZsq{}, \PYGZsq{}X14\PYGZsq{}, \PYGZsq{}X37\PYGZsq{}, \PYGZsq{}X38\PYGZsq{}, \PYGZsq{}X39\PYGZsq{}, \PYGZsq{}X40\PYGZsq{}]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{coefs} \PYG{o}{=} \PYG{n}{lars\PYGZus{}path}\PYG{p}{(}\PYG{n}{X}\PYG{o}{.}\PYG{n}{values}\PYG{p}{,} \PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{p}{,} \PYG{n}{method}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lasso}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{xx} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{abs}\PYG{p}{(}\PYG{n}{coefs}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{xx} \PYG{o}{/}\PYG{o}{=} \PYG{n}{xx}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{xx}\PYG{p}{,} \PYG{n}{coefs}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,} \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.75}\PYG{p}{)}
\PYG{n}{ymin}\PYG{p}{,} \PYG{n}{ymax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylim}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{vlines}\PYG{p}{(}\PYG{n}{xx}\PYG{p}{,} \PYG{n}{ymin}\PYG{p}{,} \PYG{n}{ymax}\PYG{p}{,} \PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dashed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{|coef| / max|coef|}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LASSO Path}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{tight}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
.
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_23_1}.png}

\sphinxstyleemphasis{\sphinxstylestrong{b: second\sphinxhyphen{}degree}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{poly} \PYG{o}{=} \PYG{n}{PolynomialFeatures}\PYG{p}{(}\PYG{n}{degree}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{include\PYGZus{}bias}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{n}{XX} \PYG{o}{=} \PYG{n}{poly}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)}
\PYG{n}{poly\PYGZus{}columns} \PYG{o}{=} \PYG{p}{[}
    \PYG{n}{col}\PYG{o}{.}\PYG{n}{replace}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{k}{for} \PYG{n}{col} \PYG{o+ow}{in} \PYG{n}{poly}\PYG{o}{.}\PYG{n}{get\PYGZus{}feature\PYGZus{}names}\PYG{p}{(}\PYG{n}{X}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{)}
\PYG{p}{]}
\PYG{n}{XX} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{,} \PYG{n}{columns}\PYG{o}{=}\PYG{n}{poly\PYGZus{}columns}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{lasso\PYGZus{}model\PYGZus{}poly} \PYG{o}{=} \PYG{n}{lasso\PYGZus{}model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}

\PYG{n}{relevant\PYGZus{}poly} \PYG{o}{=} \PYG{n}{XX}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{[}\PYG{n}{lasso\PYGZus{}model\PYGZus{}poly}\PYG{o}{.}\PYG{n}{coef\PYGZus{}} \PYG{o}{!=} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}list}\PYG{p}{(}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Relevant features chosen via Lasso:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{relevant\PYGZus{}poly}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Relevant features chosen via Lasso: [\PYGZsq{}X3\PYGZsq{}, \PYGZsq{}X5\PYGZsq{}, \PYGZsq{}X37\PYGZsq{}, \PYGZsq{}X38\PYGZsq{}, \PYGZsq{}X57\PYGZsq{}, \PYGZsq{}X92\PYGZsq{}, \PYGZsq{}X2:X12\PYGZsq{}, \PYGZsq{}X3:X4\PYGZsq{}, \PYGZsq{}X3:X5\PYGZsq{}, \PYGZsq{}X3:X12\PYGZsq{}, \PYGZsq{}X3:X57\PYGZsq{}, \PYGZsq{}X5:X9\PYGZsq{}, \PYGZsq{}X5:X92\PYGZsq{}, \PYGZsq{}X5:X99\PYGZsq{}, \PYGZsq{}X7:X12\PYGZsq{}, \PYGZsq{}X9:X12\PYGZsq{}, \PYGZsq{}X12\PYGZca{}2\PYGZsq{}, \PYGZsq{}X12:X14\PYGZsq{}, \PYGZsq{}X38\PYGZca{}2\PYGZsq{}, \PYGZsq{}X38:X39\PYGZsq{}, \PYGZsq{}X38:X40\PYGZsq{}, \PYGZsq{}X38:X57\PYGZsq{}, \PYGZsq{}X38:X92\PYGZsq{}]
\end{sphinxVerbatim}


\subparagraph{Recursive Feature Elimination with CV}
\label{\detokenize{simulated_reverse_engineering:recursive-feature-elimination-with-cv}}
As above, I will not dive too deep into the inner workings of the RFECV function as this it not my main model / model selection tool. Here I will apply it on only on the first order effects.

The main idea is to recursively consider smaller and smaller subsets of features. I use 5\sphinxhyphen{}fold CV to compute the \sphinxstyleemphasis{optimal} subset and plot the negative mean squared error against the number of features.

\sphinxstyleemphasis{\sphinxstylestrong{Note.}} As mentioned above I only include the first order effects here since the number of terms explodes when also considering the interactions terms. Still, for each included regressor one could fit a 4th degree polynomial instead of the 1st degree effect I consider below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{linear\PYGZus{}model} \PYG{o}{=} \PYG{n}{LinearRegression}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{rfecv} \PYG{o}{=} \PYG{n}{RFECV}\PYG{p}{(}\PYG{n}{estimator}\PYG{o}{=}\PYG{n}{linear\PYGZus{}model}\PYG{p}{,} \PYG{n}{step}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{cv}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{scoring}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{neg\PYGZus{}mean\PYGZus{}squared\PYGZus{}error}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{rfecv}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Optimal subset of features: }\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{X}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{[}\PYG{n}{rfecv}\PYG{o}{.}\PYG{n}{get\PYGZus{}support}\PYG{p}{(}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}list}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Optimal subset of features:  [\PYGZsq{}X3\PYGZsq{}, \PYGZsq{}X12\PYGZsq{}, \PYGZsq{}X38\PYGZsq{}]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Number of features selected}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CV score (neg\PYGZus{}mean\PYGZus{}squared\PYGZus{}error)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{rfecv}\PYG{o}{.}\PYG{n}{grid\PYGZus{}scores\PYGZus{}}\PYG{p}{)} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{rfecv}\PYG{o}{.}\PYG{n}{grid\PYGZus{}scores\PYGZus{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_29_0}.png}


\subparagraph{The Ridge Comparison Approach}
\label{\detokenize{simulated_reverse_engineering:the-ridge-comparison-approach}}
In this last approach the overall goal is to fit a third\sphinxhyphen{}degree linear model with l2 regularization, i.e. a ridge regression, for all features and plot the coefficient values with the feature index on the x\sphinxhyphen{}axis. In particular I fit the model \(Y \sim \beta_0 + \sum_{k=1}^K \beta_{1k} X_k + \beta_{2k} X_k^2 + \beta_{3k} X_k^3\) using an l2 regularization and set all coefficients which are below some threshold (here 0.75) to zero. The results are compared across \(k\). The regularization parameter is chosen via 5\sphinxhyphen{}fold cross validation.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{XX} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{concat}\PYG{p}{(}\PYG{p}{[}\PYG{n}{X} \PYG{o}{*}\PYG{o}{*} \PYG{n}{k} \PYG{k}{for} \PYG{n}{k} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{alphas} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{num}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{)}
\PYG{n}{ridge} \PYG{o}{=} \PYG{n}{RidgeCV}\PYG{p}{(}\PYG{n}{cv}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{alphas}\PYG{o}{=}\PYG{n}{alphas}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}

\PYG{n}{df\PYGZus{}coef} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}
    \PYG{n}{ridge}\PYG{o}{.}\PYG{n}{coef\PYGZus{}}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{order}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{F}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{columns}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{beta1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{beta2}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{beta3}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{index}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{X}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{)} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{p}{)}

\PYG{n}{threshold} \PYG{o}{=} \PYG{l+m+mf}{0.75}
\PYG{n}{df\PYGZus{}coef}\PYG{p}{[}\PYG{n}{df\PYGZus{}coef}\PYG{o}{.}\PYG{n}{abs}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}} \PYG{n}{threshold}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{0}
\PYG{n}{df\PYGZus{}coef} \PYG{o}{=} \PYG{n}{df\PYGZus{}coef}\PYG{o}{.}\PYG{n}{rename\PYGZus{}axis}\PYG{p}{(}
    \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{feature\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}\PYG{o}{.}\PYG{n}{reset\PYGZus{}index}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{melt}\PYG{p}{(}\PYG{n}{id\PYGZus{}vars}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{feature\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{var\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{coef}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{df\PYGZus{}coef}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{df\PYGZus{}coef}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n+nb}{float}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ax} \PYG{o}{=} \PYG{n}{sns}\PYG{o}{.}\PYG{n}{scatterplot}\PYG{p}{(}
    \PYG{n}{x}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{feature\PYGZus{}id}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{y}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{hue}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{coef}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{data}\PYG{o}{=}\PYG{n}{df\PYGZus{}coef}
\PYG{p}{)}
\PYG{n}{ymax}\PYG{p}{,} \PYG{n}{ymin} \PYG{o}{=} \PYG{n}{df\PYGZus{}coef}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{df\PYGZus{}coef}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{min}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{vlines}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{13}\PYG{p}{,} \PYG{l+m+mi}{14}\PYG{p}{,} \PYG{l+m+mi}{37}\PYG{p}{,} \PYG{l+m+mi}{38}\PYG{p}{,} \PYG{l+m+mi}{39}\PYG{p}{,} \PYG{l+m+mi}{44}\PYG{p}{]}\PYG{p}{,} \PYG{n}{ymin}\PYG{o}{=}\PYG{n}{ymin}\PYG{p}{,} \PYG{n}{ymax}\PYG{o}{=}\PYG{n}{ymax}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{black}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mf}{0.65}\PYG{p}{,} \PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dashed}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{prop}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{16}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlim}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{p}{)} \PYG{o}{+} \PYG{n+nb}{tuple}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_reverse_engineering_32_0}.png}

The dashed black lines represent features that were selected by the first\sphinxhyphen{}order Lasso approach


\subsubsection{Conclusions  (so far)}
\label{\detokenize{simulated_reverse_engineering:conclusions-so-far}}
In all of the methods considered above we have seen that only very few features are selected and accross approaches the same (or at least neighboring) features were selected consistently. This leads me to believe that, as mentioned before, the main effect of the problem is sparse. I would have enjoyed using a simple third\sphinxhyphen{}degree polynomial model with subsetted features. Sadly, when compared on the validation set I get a substantially lower prediction error using some of the machine learning methods presented next.


\subsection{Final}
\label{\detokenize{simulated_final:final}}\label{\detokenize{simulated_final::doc}}
In this last section I will list my top four models and their respective performances on the validation set. Please note that only for my final model I will explain how the fitting procedure works in detail.

I consider a
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Linear model using a subset of features

\item {} 
Deep neural network with dropout regularization

\item {} 
Two\sphinxhyphen{}stage random forest with feature selection

\item {} 
Gradient tree boosting (\sphinxstyleemphasis{the final model})

\end{enumerate}

If you only care about the final model please jump directly to subsection 4, in which I explain how the model is fit on a theoretical basis as well as how to implement it in Python. Note also that in the very last subsection I include a figure comparing the validation mean squared error for all of the presented models.


\subsubsection{Preliminaries}
\label{\detokenize{simulated_final:preliminaries}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{seaborn} \PYG{k}{as} \PYG{n+nn}{sns}

\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dropout}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{wrappers}\PYG{n+nn}{.}\PYG{n+nn}{scikit\PYGZus{}learn} \PYG{k+kn}{import} \PYG{n}{KerasRegressor}

\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LinearRegression}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{PolynomialFeatures}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{ensemble} \PYG{k+kn}{import} \PYG{n}{RandomForestRegressor}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}

\PYG{k+kn}{from} \PYG{n+nn}{catboost} \PYG{k+kn}{import} \PYG{n}{CatBoostRegressor}

\PYG{n}{ROOT} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df\PYGZus{}train} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bld}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}simulated.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{df\PYGZus{}val} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bld}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{validate\PYGZus{}simulated.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{df\PYGZus{}train}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{df\PYGZus{}train}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{y\PYGZus{}val} \PYG{o}{=} \PYG{n}{df\PYGZus{}val}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{X\PYGZus{}val} \PYG{o}{=} \PYG{n}{df\PYGZus{}val}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}


\subsubsection{1. Linear Model Using a Subset of Features}
\label{\detokenize{simulated_final:linear-model-using-a-subset-of-features}}
Here I fit a simple two\sphinxhyphen{}step 3rd degree polynomial regression model to benchmark the machine learning methods from below. The procedure has two steps as I only consider the features \(\{X_3, X_{12}, X_{38}\}\). This set of features was selected in the previous section using the recursive feature elimination strategy. However, basically all other feature selection strategies considered in the previous section selected a similar set of features.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{relevant} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{k}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{for} \PYG{n}{k} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{38}\PYG{p}{]}\PYG{p}{]}

\PYG{n}{XX\PYGZus{}train} \PYG{o}{=} \PYG{n}{X\PYGZus{}train}\PYG{p}{[}\PYG{n}{relevant}\PYG{p}{]}
\PYG{n}{XX\PYGZus{}val} \PYG{o}{=} \PYG{n}{X\PYGZus{}val}\PYG{p}{[}\PYG{n}{relevant}\PYG{p}{]}

\PYG{n}{poly} \PYG{o}{=} \PYG{n}{PolynomialFeatures}\PYG{p}{(}\PYG{n}{degree}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{include\PYGZus{}bias}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{XX\PYGZus{}train} \PYG{o}{=} \PYG{n}{poly}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{XX\PYGZus{}train}\PYG{p}{)}
\PYG{n}{XX\PYGZus{}val} \PYG{o}{=} \PYG{n}{poly}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{XX\PYGZus{}val}\PYG{p}{)}

\PYG{n}{lm} \PYG{o}{=} \PYG{n}{LinearRegression}\PYG{p}{(}\PYG{n}{n\PYGZus{}jobs}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{n}{lm}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{XX\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{lm}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{XX\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}lm} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Linear Model) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}lm}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Linear Model) MSE: 5.361621926612066
\end{sphinxVerbatim}


\subsubsection{2. Deep Neural Network with Dropout Regularization}
\label{\detokenize{simulated_final:deep-neural-network-with-dropout-regularization}}
I fit a deep neural network using the popular \sphinxhref{https://keras.io/}{keras} library (\sphinxcite{zreferences:keras}) which provides an intuitive API for the powerful \sphinxhref{https://www.tensorflow.org/}{tensorflow} package (\sphinxcite{zreferences:tensorflow}). The neural network architecture is set using the \sphinxcode{\sphinxupquote{build\_regressor}} function. I choose an archtecture with 7 layers. For the first layer I choose 50 hidden nodes, for the second layer 25 hidden nodes and for all remaining layers I choose 10 hidden nodes. Moreover I use the so called \sphinxhref{https://en.wikipedia.org/wiki/Rectifier\_(neural\_networks)}{ReLu} activation function, which has been proven to outperform the classic sigmoid activation function in several ways, see for example \sphinxcite{zreferences:krizhevsky2017}. As overfitting is a big problem with deep networks I employ a popular technique called dropout regularization to mitigate this effect, see \sphinxcite{zreferences:srivastava2014}. Dropout leads to neurons in a layer being randomly deactivated for a single epoch during the backpropagation. This avoids neighboring neurons developing a strong dependency, which is said to mitigate overfitting.

\sphinxstyleemphasis{\sphinxstylestrong{Note.}} I decide to use this specific architecture as I “learned” from the previous section that the main effects are sparse in the sense that most likely only very few features are relevant. However, I also realized from playing around with the linear model while watching the validation error that some effects must be non\sphinxhyphen{}linear. An architecture which reduces the nodes from the original 100 input dimensions to 50, then 25 and then 10, forces the network to select relevant features. And by using the additional 5 layers the network can potentially find non\sphinxhyphen{}linear signals.

\sphinxstyleemphasis{\sphinxstylestrong{Remark.}} Since the gradient boosted tree presented below performs so well I did not consider many different architectures. I do believe that the neural networks should be able to perform comparably well if a better architecture is chosen.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{N\PYGZus{}COL} \PYG{o}{=} \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{k}{def} \PYG{n+nf}{build\PYGZus{}regressor}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{regressor} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}
    \PYG{c+c1}{\PYGZsh{} first hidden layer}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}dim}\PYG{o}{=}\PYG{n}{N\PYGZus{}COL}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dropout}\PYG{p}{(}\PYG{l+m+mf}{0.2}\PYG{p}{)}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} second hidden layer}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{l+m+mi}{25}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dropout}\PYG{p}{(}\PYG{l+m+mf}{0.2}\PYG{p}{)}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} third to tenth hidden layer}
    \PYG{k}{for} \PYG{n}{\PYGZus{}} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} output layer}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{n}{units}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{linear}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} compile model}
    \PYG{n}{regressor}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{adam}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mean\PYGZus{}squared\PYGZus{}error}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{regressor}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{nnet} \PYG{o}{=} \PYG{n}{KerasRegressor}\PYG{p}{(}
    \PYG{n}{build\PYGZus{}fn}\PYG{o}{=}\PYG{n}{build\PYGZus{}regressor}\PYG{p}{,} \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{128}\PYG{p}{,} \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{200}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{nnet}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{nnet}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}nnet} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Neural Network) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}nnet}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Neural Network) MSE: 5.289789777325298
\end{sphinxVerbatim}


\subsubsection{3. Two\sphinxhyphen{}stage Random Forest with Feature Selection}
\label{\detokenize{simulated_final:two-stage-random-forest-with-feature-selection}}
In this two stage procedure I first fit a random forest on the full set of features. I then consider the standard feature importance measure of random forests, which is automatically calculated from the fitting procedure. Using this I select the 30 \sphinxstyleemphasis{most} important features and fit another random forest on this subset of features.

\sphinxstyleemphasis{\sphinxstylestrong{First Stage}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{rf} \PYG{o}{=} \PYG{n}{RandomForestRegressor}\PYG{p}{(}
    \PYG{n}{n\PYGZus{}estimators}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} 
    \PYG{n}{max\PYGZus{}features}\PYG{o}{=}\PYG{l+m+mi}{25}\PYG{p}{,} 
    \PYG{n}{max\PYGZus{}depth}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}
    \PYG{n}{min\PYGZus{}samples\PYGZus{}leaf}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{,}
    \PYG{n}{bootstrap}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{n\PYGZus{}jobs}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,}
    \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{rf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{o}{.}\PYG{n}{values}\PYG{p}{)}

\PYG{n}{std} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}
    \PYG{p}{[}\PYG{n}{tree}\PYG{o}{.}\PYG{n}{feature\PYGZus{}importances\PYGZus{}} \PYG{k}{for} \PYG{n}{tree} \PYG{o+ow}{in} \PYG{n}{rf}\PYG{o}{.}\PYG{n}{estimators\PYGZus{}}\PYG{p}{]}\PYG{p}{,} 
    \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{p}{)}
\PYG{n}{indices} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argsort}\PYG{p}{(}\PYG{n}{rf}\PYG{o}{.}\PYG{n}{feature\PYGZus{}importances\PYGZus{}}\PYG{p}{)}\PYG{p}{[}\PYG{p}{:}\PYG{p}{:}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{relevant} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{X}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{indices}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{30}\PYG{p}{]}\PYG{p}{]}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{rf}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}first\PYGZus{}stage} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{First stage MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}first\PYGZus{}stage}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
First stage MSE: 5.1615609346407565
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} plotting code: can be safely ignored}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{rcParams}\PYG{o}{.}\PYG{n}{update}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{font.size}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{figure.figsize}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\PYG{n}{cut} \PYG{o}{=} \PYG{l+m+mi}{40}
\PYG{n}{x} \PYG{o}{=} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{[}\PYG{p}{:}\PYG{n}{cut}\PYG{p}{]}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{rf}\PYG{o}{.}\PYG{n}{feature\PYGZus{}importances\PYGZus{}}\PYG{p}{[}\PYG{n}{indices}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{n}{cut}\PYG{p}{]}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Feature importances (displaying only the }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{cut}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{ most important features)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{yerr}\PYG{o}{=}\PYG{n}{std}\PYG{p}{[}\PYG{n}{indices}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{n}{cut}\PYG{p}{]}\PYG{p}{,} \PYG{n}{align}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{center}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{indices}\PYG{p}{[}\PYG{p}{:}\PYG{n}{cut}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlim}\PYG{p}{(}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{cut}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_final_11_0}.png}

\sphinxstyleemphasis{\sphinxstylestrong{Second Stage}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{XX\PYGZus{}train} \PYG{o}{=} \PYG{n}{X\PYGZus{}train}\PYG{p}{[}\PYG{n}{relevant}\PYG{p}{]}
\PYG{n}{XX\PYGZus{}val} \PYG{o}{=} \PYG{n}{X\PYGZus{}val}\PYG{p}{[}\PYG{n}{relevant}\PYG{p}{]}

\PYG{n}{rf} \PYG{o}{=} \PYG{n}{RandomForestRegressor}\PYG{p}{(}
    \PYG{n}{n\PYGZus{}estimators}\PYG{o}{=}\PYG{l+m+mi}{250}\PYG{p}{,} 
    \PYG{n}{max\PYGZus{}features}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,} 
    \PYG{n}{max\PYGZus{}depth}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}
    \PYG{n}{min\PYGZus{}samples\PYGZus{}leaf}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{,}
    \PYG{n}{bootstrap}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{n\PYGZus{}jobs}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{,}
    \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{rf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{XX\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{o}{.}\PYG{n}{values}\PYG{p}{)}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{rf}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{XX\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}rf} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Random Forest) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}rf}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Random Forest) MSE: 5.120511556417796
\end{sphinxVerbatim}


\subsubsection{4. Gradient tree boosting (\sphinxstyleemphasis{the final model})}
\label{\detokenize{simulated_final:gradient-tree-boosting-the-final-model}}
The final model I decided to use is a specific variant of a gradient boosted tree. The key concepts of this method are equivalent to the algorithm proposed in the seminal paper by Friedman, see \sphinxcite{zreferences:friedman2002}. The version I am using is implemented in the \sphinxhref{https://catboost.ai/}{catboost} package, which differs slightly from common other implementations. Next I will introduce the theoretical concept of gradient boosting with a particular focus on tree weak\sphinxhyphen{}learners. Afterwards I show how to fit a model using \sphinxcode{\sphinxupquote{catboost}}.

\sphinxstyleemphasis{\sphinxstylestrong{Note.}} My final prediction submissions are made with the exact model specification as presented in below, but using the complete training data. The corresponding script can be found here \sphinxhref{https://github.com/timmens/topics-project/blob/main/codes/final\_prediction.py}{final\_prediction.py}.


\paragraph{Theory}
\label{\detokenize{simulated_final:theory}}
I will first explain the general idea behind boosting and gradient boosting. Then I show how the general formulas simplify when using (regression) trees as base\sphinxhyphen{}learners. At last I illustrate how out\sphinxhyphen{}of\sphinxhyphen{}sample prediction loss may be improved by using ideas from stochastic gradient descent and regularization.

\sphinxstyleemphasis{\sphinxstylestrong{Note.}} My notation and explaination is guided by \sphinxcite{zreferences:friedman2002} and \sphinxcite{zreferences:esl2001}.


\bigskip\hrule\bigskip


\sphinxstylestrong{Notation and Preliminaries}

Assume we are given a data set \(\{(x_i, y_i) : i=1,\dots,N\}\), with \(x_i \in \mathbb{R}^p\) and \(y_i \in \mathbb{R}\). These observations are assumed to be i.i.d. according to some joint distribution \(\mathbb{P}_{xy}\). An important goal of statistical learning is to find a function \(f^* : \mathbb{R}^p \to \mathbb{R}\) such that

\textbackslash{}begin\{align*\}
f\textasciicircum{}* = \textbackslash{}underset\{f\}\{\textbackslash{}text\{argmin\}\} , \textbackslash{}mathbb\{E\}\textasciicircum{}\{xy\} \textbackslash{}left {[}L(y, f(x)) \textbackslash{}right{]},
\textbackslash{}end\{align*\}
given some loss function \(L\), where the expectation is taken over the joint distribution of \(x\) and \(y\) values.

As is very common in statistical learning, boosting is a procedure to approximate \(f^*\) by an additive model of the form

\textbackslash{}begin\{align*\}
f(x) = \textbackslash{}sum\_\{m=0\}\textasciicircum{}M \textbackslash{}beta\_m b(x; \textbackslash{}gamma\_m),
\textbackslash{}end\{align*\}
where the \(\beta_m\) denote expansion coefficients and \(b(\cdot\,,\gamma) : \mathbb{R}^p \to \mathbb{R}\) denote the so called \sphinxstyleemphasis{base\sphinxhyphen{}learners} which are parameterized by \(\gamma\). If feasible in general we would like to estimate the parameters by solving

\textbackslash{}begin\{align*\}
\textbackslash{}underset\{\{\textbackslash{}beta\_m, \textbackslash{}gamma\_m\}\sphinxstyleemphasis{1\textasciicircum{}M\}\{\textbackslash{}min\}  \textbackslash{}sum}\{i=1\}\textasciicircum{}N L\textbackslash{}left(y\_i, \textbackslash{}sum\_\{m=0\}\textasciicircum{}M \textbackslash{}beta\_m b(x\_i; \textbackslash{}gamma\_m)\textbackslash{}right).
\textbackslash{}end\{align*\}

For a general loss function and base\sphinxhyphen{}learner, however, this optimization is computationally intractable. We will also see that there are other reasons why we would like to estimate the coefficients in a different fashion.


\bigskip\hrule\bigskip


\sphinxstylestrong{General Concept}

A simple algorithm to approximate the coefficient estimates from above is to fit each tuple \((\beta_m, \gamma_m)\) in a stage\sphinxhyphen{}wise fashion. That is, one starts with an initial guess \(f_0\) and then

for each \(m=1,\dots, M\) do:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\((\beta_m, \gamma_m) = \underset{\beta, \gamma}{\text{argmin}} \, \sum_{i=1}^N L \left(y_i, f_{m-1}(x_i) + \beta b(x_i; \gamma) \right)\)

\item {} 
\(f_m(x) = f_{m-1}(x) + \beta_m b(x, \gamma_m)\).

\end{enumerate}

This simplifies the optimization problem from above consideribly, but again, for general loss functions and base\sphinxhyphen{}learners step 1 can be hard to solve.


\bigskip\hrule\bigskip


\sphinxstylestrong{Gradient Boosting}

Gradient boosting, as proposed in \sphinxcite{zreferences:friedman2000}, approximately solves the first step from above for differentiable loss functions using a three step procedure. In the \(m\)\sphinxhyphen{}th loop from above we do
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\(r_{im} := - \left[\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}  \right]_{f(x) = f_{m-1}(x)}\)

\item {} 
\(\gamma_m = \underset{\gamma, \rho}{\text{argmin}} \, \sum_{i=1}^N \left(r_{im} - \rho b(x_i; \gamma) \right)^2\)

\item {} 
\(\beta_m = \underset{\beta}{\text{argmin}} \, \sum_{i=1}^N L \left(y_i, f_{m-1}(x_i) + \beta b(x_i; \gamma_m) \right)\).

\end{enumerate}

That is, we first compute the gradient, whose entries we call \sphinxstyleemphasis{pseudo\sphinxhyphen{}residuals}, and then we fit a single base\sphinxhyphen{}learner using the least\sphinxhyphen{}squares method. Lastly we have to solve a general optimization problem, but only in a single variable, which can be done efficiently with state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art optimization algorithms.

With squared\sphinxhyphen{}error loss (\(L(y, x) = \frac{1}{2}(y - x)^2\)) the pseudo\sphinxhyphen{}residuals \(r_{im}\) are equivalent to the actual residuals \(r_{im} = y_i - f_{m-1}(x_i)\). This allows for the nice interpretation of the procedure that given any step \(m\), we consider the deviations of the labels \(y_i\) from our current estimate \(f_{m-1}(x_i)\) and train a model to fit these deviations. I.e. in each iterations the model tries to improve the fit in the regions where the fit is worst. With other loss functions, say absolute\sphinxhyphen{}error loss (\(L(y, x) = |y - x|\)) we get \(r_{im} = \text{sign}(y_i - f_{m-1}(x_i))\) and in the \(m\)\sphinxhyphen{}th step the base\sphinxhyphen{}learner is fit to simply predict the direction to which a sample deviates, which is more robust to outliers as it ignores the magnitude of the deviation.


\bigskip\hrule\bigskip


\sphinxstylestrong{Gradient Tree Boosting}

A popular choice of base\sphinxhyphen{}learners are decision trees. When using trees as base learners some steps in the generic algorithm simplify and some can even be improved. First, let us formally define a tree. A regression tree with \(J\) terminal\sphinxhyphen{}nodes is a function

\textbackslash{}begin\{align*\}
T\textbackslash{}left(x; \{\textbackslash{}alpha\_j, R\_j\}\sphinxstyleemphasis{\{j=1\}\textasciicircum{}J \textbackslash{}right) = \textbackslash{}sum}\{j=1\}\textasciicircum{}J \textbackslash{}alpha\_j \textbackslash{}mathbb\{1\}\sphinxstyleemphasis{\{R}\{j\}\}(x),
\textbackslash{}end\{align*\}
where \(\{R_j\}_{j=1}^J\) is a partition of the feature space \(\mathbb{R}^p\). Strictly speaking, \(J\) is also a parameter, however, it is usually considered a \sphinxstyleemphasis{hyper\sphinxhyphen{}parameter} which has to be chosen using prior information or via methods like cross\sphinxhyphen{}validation.

Let us now consider the second step of the above algorithm. First note that optimizing over \(\rho\) is irrelevant in the case of trees as we can always define \(\tilde{\alpha}_j := \rho \alpha_j\). But then solving 2 is equivalent to solving

\textbackslash{}begin\{align*\}
\{\textbackslash{}alpha\_\{jm\}, R\_\{jm\}\}\sphinxstyleemphasis{\{j=1\}\textasciicircum{}J =: \textbackslash{}gamma\_m = \textbackslash{}underset\{\textbackslash{}gamma\}\{\textbackslash{}text\{argmin\}\} , \textbackslash{}sum}\{i=1\}\textasciicircum{}N \textbackslash{}left(r\_\{im\} \sphinxhyphen{} T(x\_i; \textbackslash{}gamma) \textbackslash{}right)\textasciicircum{}2
\textbackslash{}end\{align*\}
For a given \(J\) this combinatorial optimization problem is again computationally intractable, but there are many algorithms that can approximate the solution; see for example the CART algorithm in \sphinxcite{zreferences:esl2001}.

Henceforth say we have (approximately) solved the tree optimization problem (step 2) and are left to optimize for the constant \(\beta_m\) (step 3). As will be seen, with trees we can even go one step further and choose an optimal value for each terminal\sphinxhyphen{}node region. Let \(\gamma_m = \{\alpha_j, R_j\}_{j=1}^J\) be the fitted parameters from step 2. The next simplification when using trees stems from the fact the the \(R_j\)’s form a partition of the feature space. We can rewrite the sum over the individuals as a sum over the terminal\sphinxhyphen{}node regions, as a tree predicts the same value for each region. That is, step 3 becomes

\textbackslash{}begin\{align*\}
\{\textbackslash{}beta\_\{jm\}\}\sphinxstyleemphasis{\{j=1\}\textasciicircum{}J = \textbackslash{}underset\{\textbackslash{}beta\_1,\textbackslash{}dots,\textbackslash{}beta\_J\}\{\textbackslash{}text\{argmin\}\} , \textbackslash{}sum}\{j=1\}\textasciicircum{}J \textbackslash{}sum\_\{x\_i \textbackslash{}in R\_j\} L \textbackslash{}left(y\_i, f\_\{m\sphinxhyphen{}1\}(x\_i) + \textbackslash{}beta\_j \textbackslash{}right) ,,
\textbackslash{}end\{align*\}
which can be solved for each region seperately. Note that we can write \(L \left(y_i, f_{m-1}(x_i) + \beta_j \right)\) instead of \(L \left(y_i, f_{m-1}(x_i) + \beta_j \alpha_j \right)\).

As an example, with squared error loss we would then get \(\beta_{jm} = \text{mean}(y_i - f_{m-1}(x_i) : x_i \in R_{jm}) = \text{mean}(r_{im} : x_i \in R_{jm})\).


\bigskip\hrule\bigskip


\sphinxstylestrong{Algorithm}

For the sake of clarity I illustrate the complete gradient tree boosting algorithm. This corresponds to Algorithm 10.3 (Gradient Tree Boosting Algorithm) in \sphinxcite{zreferences:esl2001} with minor modifications.

\sphinxstyleemphasis{Input}: \(M\) (number of trees), \(J\) (number of terminal nodes), \(L\) (loss function), \(\{(x_i, y_i)\}_{i=1}^N\) (training data).
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\(f_0 = \underset{\gamma}{\text{argmin}} \sum_{i=1}^N L(y_i, \gamma)\)

\item {} 
For \(m = 1, \dots, M\):
\begin{itemize}
\item {} 
a) For \(i=1,\dots,N\) compute \(r_{im} := - \left[\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}  \right]_{f = f_{m-1}}\)

\item {} 
b) Fit a tree to \(\{(x_i, r_{im})\}_{i=1}^N\) resulting in regions \(\{R_{jm}\}_{j=1}^J\)

\item {} 
c) For \(j=1,\dots,J\) solve \(\gamma_{jm} = \underset{\gamma}{\text{argmin}} \sum_{x_i \in R_{jm}} L(y_i, f_{m-1}(x_i) + \gamma)\)

\item {} 
d) Update \(f_m = f_{m-1} + \sum_{j=1}^J \gamma_{jm} \mathbb{1}_{R_{jm}}\)

\end{itemize}

\item {} 
Return \(f = f_M\)

\end{enumerate}


\bigskip\hrule\bigskip


\sphinxstylestrong{Enhancements}

Until now we have not mentioned two key concepts used widely in the statistical and machine learning literature. \sphinxstyleemphasis{Injecting randomness}, which is used to decorrelate trees and therefore to avoid overfitting, and \sphinxstyleemphasis{regularization}, which is is also used to avoid overfitting.
\begin{itemize}
\item {} 
\sphinxstyleemphasis{\sphinxstylestrong{Injecting Randomness.}}
From empirical experience it has been seen that methods like bagging \sphinxcite{zreferences:breiman96} and random forests \sphinxcite{zreferences:breiman2001} outperform similar algorithms that do not explicitly make use of randomness. Similarly stochastic gradient descent is considered superior to the classical gradient descent algorithm when used in a machine learning setting; see \sphinxcite{zreferences:bottou2016}. The easiest way to inject randomness to the gradient boosting algorithm is described in \sphinxcite{zreferences:friedman2002}. In the second step of the above algorithm we simply consider a randommly shuffled subset of the data of size \(N' < N\). On top of potentially improving out\sphinxhyphen{}of\sphinxhyphen{}sample fit, this can lead to significantly shorter training times.

\item {} 
\sphinxstyleemphasis{\sphinxstylestrong{Regularization.}}
Similarly as injecting randomness, a popular technique to avoid overfitting is regularization. Especially shrinkage methods like ridge regression and lasso have gained immense popularity; see for example \sphinxcite{zreferences:slws2015}. An immediate enhancement to the above algorithm is to include a shrinkage paramater \(0 < \nu \leq 1\) in the updating step, which is usually called the \sphinxstyleemphasis{learning rate}. In step 2.d) we then modify the equation slightly to get
\(f_m = f_{m-1} + \nu \sum_{j=1}^J \gamma_{jm} \mathbb{1}_{R_{jm}}\).
It was found empirically that small values of the learning rate, \(\nu < 0.1\), lead to better generalization; see \sphinxcite{zreferences:friedman2000}.

\end{itemize}


\bigskip\hrule\bigskip


\sphinxstylestrong{Catboost}

Catboost is an open\sphinxhyphen{}source library for gradient boosting on decision trees. Its implementation differs slighty from the above algorithm. As of right now it outperforms or ties with most other open\sphinxhyphen{}source boosting libraries such as \sphinxhref{https://lightgbm.readthedocs.io/en/latest/}{LightGBM}, \sphinxhref{https://xgboost.readthedocs.io/en/latest/}{XGBoost} and \sphinxhref{https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/gbm.html}{H2O}; see the benchmarks \sphinxhref{https://catboost.ai/\#benchmark}{here}. Next I will list the main differences and refer to the respective papers for reference.
\begin{itemize}
\item {} 
\sphinxstyleemphasis{\sphinxstylestrong{Categorical Features.}}
The main new feature in \sphinxcode{\sphinxupquote{catboost}} is the clever support of categorical features. Decision trees cannot usally deal with categorical features with more than 2 states. (This is of course because the binary relation “\(\leq\)” must not be defined on the discrete space.) A common approach is the so called \sphinxstyleemphasis{one\sphinxhyphen{}hot} encoding, where we introduce a new binary feature for the activation of each state. If the feature set includes many categorical features and the state space is large for many, then one\sphinxhyphen{}hot encoding can blow up the dimensionality of the problem to a problematic extent. Another approach is to use target statistics, in which we try to map the categorical features to numerical ones. Consider a categorical feature and let it be denoted by the \(k\)\sphinxhyphen{}th feature. Frequently the target statistic is chosen as to approximate the conditional mean, i.e. \(\tilde{x}_{ik} \approx \mathbb{E}_{xy}\left[y \mid x = x_{ik}\right]\). See \sphinxcite{zreferences:dorogush2018} for details.

\item {} 
\sphinxstyleemphasis{\sphinxstylestrong{Unbiased Gradients.}}
It is argued in \sphinxcite{zreferences:dorogush2017} that gradient boosting suffers from a bias generated by using biased gradient estimates, which leads to overfitting. Theorem 1 in \sphinxcite{zreferences:prokhorenkova2017} proves this result under some conditions on the algorithm. A solution to avoid this effect is proposed in the above papers and implemented in \sphinxcode{\sphinxupquote{catboost}}.

\item {} 
\sphinxstyleemphasis{\sphinxstylestrong{Oblivious Trees.}}
The base\sphinxhyphen{}learner used in \sphinxcode{\sphinxupquote{catboost}} is not a regular decision tree but an \sphinxstyleemphasis{oblivious tree}, sometimes also called a \sphinxstyleemphasis{decision table}. The main difference to regular decision trees is that all nodes on a given level have to split on the same feature and the same point. This is why oblivious trees are usually longer than standard trees since they need more levels to capture non\sphinxhyphen{}linearities. Recently this form of tree structure has captured attention in the machine learning community and is being used often together with gradient boosting machines; see for example \sphinxcite{zreferences:yin2017}, \sphinxcite{zreferences:ferov2016} and \sphinxcite{zreferences:popov2019}. For a general definition of oblivious trees see \sphinxcite{zreferences:kohavi1995}.

\end{itemize}


\bigskip\hrule\bigskip


\sphinxstyleemphasis{\sphinxstylestrong{Final Remark on the Theory.}}

In the above I have talked about the (historical) development of the gradient tree boosting algorithm, however, I have not explained why boosting achieves the goal of function approximation so well. Given the standard squared\sphinxhyphen{}error loss it is known that the function \(f^*\) which minimizes the expected loss is the conditional expectation \(f^*(x) = \mathbb{E}_{xy}\left[y \mid x=x\right]\). Do we have any guarantee that boosting is at least point wise consistent then? Specific variants of the boosting algorithm and consistency thereof have been of interest in the recent literature; see \sphinxcite{zreferences:biau2017} or \sphinxcite{zreferences:lu2019}. For the very first boosting algorithm (which was actually used for classification) \sphinxcite{zreferences:platt2007} show consistency under regularity conditions. At last \sphinxcite{zreferences:yu2005} consider consistency of the boosting algorithm under early\sphinxhyphen{}stopping.


\paragraph{Implementation / Application}
\label{\detokenize{simulated_final:implementation-application}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gbt} \PYG{o}{=} \PYG{n}{CatBoostRegressor}\PYG{p}{(}
    \PYG{n}{iterations}\PYG{o}{=}\PYG{l+m+mi}{1500}\PYG{p}{,}
    \PYG{n}{learning\PYGZus{}rate}\PYG{o}{=}\PYG{l+m+mf}{0.01}\PYG{p}{,} 
    \PYG{n}{depth}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,}
    \PYG{n}{loss\PYGZus{}function}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{RMSE}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
\PYG{p}{)}
\PYG{n}{gbt}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{gbt}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}gbt} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Catboost) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}gbt}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Catboost) MSE: 5.048105271497743
\end{sphinxVerbatim}


\subsubsection{MSE Comparison}
\label{\detokenize{simulated_final:mse-comparison}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{models} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lm}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nnet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rf}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{catboost}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{mses} \PYG{o}{=} \PYG{p}{[}\PYG{n}{mse\PYGZus{}lm}\PYG{p}{,} \PYG{n}{mse\PYGZus{}nnet}\PYG{p}{,} \PYG{n}{mse\PYGZus{}rf}\PYG{p}{,} \PYG{n}{mse\PYGZus{}gbt}\PYG{p}{]}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}\PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{models}\PYG{p}{,} \PYG{n}{mses}\PYG{p}{)}\PYG{p}{,} \PYG{n}{columns}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mse}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{sns}\PYG{o}{.}\PYG{n}{set\PYGZus{}style}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{whitegrid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylim}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mf}{5.5}\PYG{p}{)}
\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{sns}\PYG{o}{.}\PYG{n}{scatterplot}\PYG{p}{(}
    \PYG{n}{x}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{y}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mse}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{data}\PYG{o}{=}\PYG{n}{data}\PYG{p}{,} \PYG{n}{hue}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{model}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{s}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{,} \PYG{n}{legend}\PYG{o}{=}\PYG{k+kc}{None}
\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{simulated_final_25_0}.png}


\section{Stock Data}
\label{\detokenize{stock:stock-data}}\label{\detokenize{stock::doc}}
In the following sections I present my investigation of the stock data set. Again, I start with a quick exploration of the data set as well as a short explaination of how I chose to split the data into training and validation samples. Then I jump directly to the last section where I present my final model and some benchmarks.


\subsection{Data Description}
\label{\detokenize{stock_intro:data-description}}\label{\detokenize{stock_intro::doc}}
In the following I will present my model for the stock data set. Before I could fit my final model I had to transform the data. Next I will discuss how I changed the data structure and how I chose split the data intro training and validation parts.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{n}{ROOT} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{data}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{stock\PYGZus{}data.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{df}\PYG{o}{.}\PYG{n}{iloc}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
         date         Y      a2me       aoa        at    at\PYGZus{}adj       ato  \PYGZbs{}
0  1965\PYGZhy{}01\PYGZhy{}31  0.461364  0.513089  0.282723  0.787958  0.319372  0.172775   
1  1965\PYGZhy{}01\PYGZhy{}31  0.542868  0.240838  0.774869  0.939791  0.340314  0.183246   
2  1965\PYGZhy{}01\PYGZhy{}31  0.249849  0.633508  0.096859  0.222513  0.884817  0.785340   
3  1965\PYGZhy{}01\PYGZhy{}31  0.371568  0.439791  0.463351  0.903141  0.434555  0.112565   
4  1965\PYGZhy{}01\PYGZhy{}31 \PYGZhy{}0.177803  0.654450  0.335079  0.704188  0.958115  0.848168   

       beme  beme\PYGZus{}adj      beta  
0  0.484293  0.609948  0.335079  
1  0.232984  0.308901  0.526178  
2  0.774869  0.787958  0.853403  
3  0.494764  0.643979  0.570681  
4  0.549738  0.793194  0.866492  
\end{sphinxVerbatim}

The original data set contains 1\_629\_155 observations of stock returns including 63 features. One of these features which is of particular importance is the date. In comparison to classical panel data, however, the above data does not have a unit index. That is, we cannot know which units move between time periods. Observations are measured from the 01.31.1965 until the 31.05.2014. Again, as in the simulated case, testing observations are marked with a \sphinxcode{\sphinxupquote{NaN}} in the outcome column. Here the testing observations are all observations starting from the 31.01.2004 until the last observed time period.


\subsubsection{Cleaning the Data}
\label{\detokenize{stock_intro:cleaning-the-data}}
Before training my models I cleaned the data in several ways. First, I transformed the date column to a year column and a one\sphinxhyphen{}hot\sphinxhyphen{}encoded quarter column. I.e., \sphinxcode{\sphinxupquote{data = 1965\sphinxhyphen{}01\sphinxhyphen{}31}} becomes \sphinxcode{\sphinxupquote{year = 1965}} and all dummies will be zero, as the first quarter is integrated in the intercept. I then dropped all observations older than 1990. I did this since I believed that the any information in the data of the ’70s\sphinxhyphen{}’90s which could be used to explain stock returns was unlikely to still explain modern stock returns. Also I wanted to reduce the size of the data set. At last I dropped all observations which had absolute returns greater than 6, as from looking at a fine histogram, these seemed to be outliers. The data cleaning script can be found here \sphinxhref{https://github.com/timmens/topics-project/blob/main/codes/clean\_data.py}{clean\_data.py}.


\subsubsection{Train / Validation Split}
\label{\detokenize{stock_intro:train-validation-split}}
As I did not want to ignore the time dimension for the train / validation split I constructed the respective sets as follows. I grouped the cleaned data set into sets by year. For each year I split the respective set into 80\% training and 20\% validation set. Lastly I concatened the smaller sets together to form the final training and validation sets. Using this strategy I can train my model on all time\sphinxhyphen{}periods and evaluate the performance on all time\sphinxhyphen{}periods. The specific implementation is given in the script \sphinxhref{https://github.com/timmens/topics-project/blob/main/codes/train\_test\_split.py}{train\_test\_split.py}.


\subsection{Final}
\label{\detokenize{stock_final:final}}\label{\detokenize{stock_final::doc}}
My final prediction model is build on the transformed data set from the previous section. In the following I consider three models.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Linear model

\item {} 
Two\sphinxhyphen{}stage linear model (\sphinxstyleemphasis{the final model})

\end{enumerate}

Again, if you only care about the final model please jump directly to subsection 2.


\subsubsection{Preliminaries}
\label{\detokenize{stock_final:preliminaries}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{seaborn} \PYG{k}{as} \PYG{n+nn}{sns}

\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{PolynomialFeatures}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LinearRegression}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LassoCV}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}

\PYG{n}{ROOT} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{df\PYGZus{}train} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bld}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train\PYGZus{}stock.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{df\PYGZus{}val} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}parquet}\PYG{p}{(}\PYG{n}{ROOT} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{bld}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{/} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{validate\PYGZus{}stock.parquet}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{df\PYGZus{}train}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{df\PYGZus{}train}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{n}{y\PYGZus{}val} \PYG{o}{=} \PYG{n}{df\PYGZus{}val}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}
\PYG{n}{X\PYGZus{}val} \PYG{o}{=} \PYG{n}{df\PYGZus{}val}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Y}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}


\subsubsection{1. Linear Model}
\label{\detokenize{stock_final:linear-model}}
Here I fit a simple unregularized linear model which is used as a lower benchmark.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{lm} \PYG{o}{=} \PYG{n}{LinearRegression}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{lm}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}

\PYG{n}{prediction} \PYG{o}{=} \PYG{n}{lm}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}lm} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{prediction}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Linear Model) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}lm}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Linear Model) MSE: 0.9494373195140412
\end{sphinxVerbatim}


\subsubsection{2. Two\sphinxhyphen{}stage Linear Model (\sphinxstyleemphasis{final model})}
\label{\detokenize{stock_final:two-stage-linear-model-final-model}}
To mix things up, here I select features using a Lasso approach. With these features I then fit a simple 2nd degree polynomial model. The code which I used to construct the final predictions can be found in the script \sphinxhref{https://github.com/timmens/topics-project/blob/main/codes/final\_prediction.py}{final\_prediction.py}.

\sphinxstyleemphasis{\sphinxstylestrong{Lasso feature selection}}

The regularization parameter is selected via a 5\sphinxhyphen{}fold cross\sphinxhyphen{}validation procedure over a logspace grid (a sequence which is linear on a logarithmic scale). I select all columns which have nonzero coefficients.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{lasso\PYGZus{}model} \PYG{o}{=} \PYG{n}{LassoCV}\PYG{p}{(}\PYG{n}{alphas}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{2.5}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cv}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{lasso\PYGZus{}model} \PYG{o}{=} \PYG{n}{lasso\PYGZus{}model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}

\PYG{n}{relevant} \PYG{o}{=} \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{[}\PYG{n}{lasso\PYGZus{}model}\PYG{o}{.}\PYG{n}{coef\PYGZus{}} \PYG{o}{!=} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}list}\PYG{p}{(}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Relevant features chosen via Lasso:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{relevant}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Relevant features chosen via Lasso:
[\PYGZsq{}at\PYGZus{}adj\PYGZsq{}, \PYGZsq{}beme\PYGZsq{}, \PYGZsq{}cum\PYGZus{}return\PYGZus{}12\PYGZus{}2\PYGZsq{}, \PYGZsq{}cum\PYGZus{}return\PYGZus{}12\PYGZus{}7\PYGZsq{}, \PYGZsq{}cum\PYGZus{}return\PYGZus{}1\PYGZus{}0\PYGZsq{}, \PYGZsq{}cum\PYGZus{}return\PYGZus{}36\PYGZus{}13\PYGZsq{}, \PYGZsq{}d\PYGZus{}so\PYGZsq{}, \PYGZsq{}e2p\PYGZsq{}, \PYGZsq{}free\PYGZus{}cf\PYGZsq{}, \PYGZsq{}noa\PYGZsq{}, \PYGZsq{}pcm\PYGZsq{}, \PYGZsq{}pm\PYGZsq{}, \PYGZsq{}pm\PYGZus{}adj\PYGZsq{}, \PYGZsq{}ret\PYGZus{}max\PYGZsq{}, \PYGZsq{}suv\PYGZsq{}, \PYGZsq{}year\PYGZsq{}, \PYGZsq{}quarter3\PYGZsq{}, \PYGZsq{}quarter4\PYGZsq{}]
\end{sphinxVerbatim}

\sphinxstyleemphasis{\sphinxstylestrong{Polynomial regression on subset}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}features}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{relevant\PYGZus{}columns}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Return 2nd degree polynomial features plus third power.\PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{poly} \PYG{o}{=} \PYG{n}{PolynomialFeatures}\PYG{p}{(}\PYG{n}{degree}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{include\PYGZus{}bias}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
    \PYG{n}{XX} \PYG{o}{=} \PYG{n}{poly}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{X}\PYG{p}{[}\PYG{n}{relevant\PYGZus{}columns}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{XX} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{concatenate}\PYG{p}{(}\PYG{p}{(}\PYG{n}{XX}\PYG{p}{,} \PYG{n}{X} \PYG{o}{*}\PYG{o}{*} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{XX}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{XX\PYGZus{}train} \PYG{o}{=} \PYG{n}{make\PYGZus{}features}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{,} \PYG{n}{relevant}\PYG{p}{)}
\PYG{n}{XX\PYGZus{}val} \PYG{o}{=} \PYG{n}{make\PYGZus{}features}\PYG{p}{(}\PYG{n}{X\PYGZus{}val}\PYG{p}{,} \PYG{n}{relevant}\PYG{p}{)}

\PYG{n}{pm} \PYG{o}{=} \PYG{n}{LinearRegression}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{pm}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{XX\PYGZus{}train}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\PYG{k}{del} \PYG{n}{XX\PYGZus{}train} \PYG{c+c1}{\PYGZsh{} memory ...}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predictions} \PYG{o}{=} \PYG{n}{pm}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{XX\PYGZus{}val}\PYG{p}{)}
\PYG{n}{mse\PYGZus{}pm} \PYG{o}{=} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}\PYG{p}{(}\PYG{n}{y\PYGZus{}val}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(Lasso Polynomial Model) MSE: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{mse\PYGZus{}pm}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Lasso Polynomial Model) MSE: 0.94026689736296
\end{sphinxVerbatim}


\section{Bibliography}
\label{\detokenize{zreferences:bibliography}}\label{\detokenize{zreferences::doc}}


\begin{sphinxthebibliography}{FModry16}
\bibitem[AAB+15]{zreferences:tensorflow}
Mart’ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: large\sphinxhyphen{}scale machine learning on heterogeneous systems. 2015. Software available from tensorflow.org. URL: \sphinxurl{https://www.tensorflow.org/}.
\bibitem[BC17]{zreferences:biau2017}
Gérard Biau and Benoît Cadre. Optimization by gradient boosting. 2017. \sphinxhref{https://arxiv.org/abs/1707.05023}{arXiv:1707.05023}.
\bibitem[BCN16]{zreferences:bottou2016}
Léon Bottou, Frank E. Curtis, and Jorge Nocedal. Optimization methods for large\sphinxhyphen{}scale machine learning. 2016. quantization overview. URL: \sphinxurl{https://arxiv.org/abs/1606.04838}, \sphinxhref{https://arxiv.org/abs/arXiv:1606.04838}{arXiv:arXiv:1606.04838}.
\bibitem[Bre96]{zreferences:breiman96}
Leo Breiman. Bagging predictors. \sphinxstyleemphasis{Machine Learning}, 24(2):123\textendash{}140, 1996.
\bibitem[Bre01]{zreferences:breiman2001}
Leo Breiman. Random forests. \sphinxstyleemphasis{Machine Learning}, 45(1):5\textendash{}32, 2001. URL: \sphinxurl{http://dx.doi.org/10.1023/A\%3A1010933404324}, \sphinxhref{https://doi.org/10.1023/A:1010933404324}{doi:10.1023/A:1010933404324}.
\bibitem[C+15]{zreferences:keras}
Francois Chollet and others. Keras. 2015. URL: \sphinxurl{https://github.com/fchollet/keras}.
\bibitem[DEG18]{zreferences:dorogush2018}
Anna Veronika Dorogush, V. Ershov, and A. Gulin. Catboost: gradient boosting with categorical features support. \sphinxstyleemphasis{ArXiv}, 2018.
\bibitem[DGG+17]{zreferences:dorogush2017}
Anna Veronika Dorogush, Andrey Gulin, Gleb Gusev, Nikita Kazeev, Liudmila Ostroumova, and Aleksandr Vorobev. Fighting biases with dynamic boosting. \sphinxstyleemphasis{ArXiv}, 2017.
\bibitem[FModry16]{zreferences:ferov2016}
Michal Ferov and Marek Modrý. Enhancing lambdamart using oblivious trees. \sphinxstyleemphasis{ArXiv}, 2016.
\bibitem[Fri00]{zreferences:friedman2000}
Jerome H. Friedman. Greedy function approximation: a gradient boosting machine. \sphinxstyleemphasis{Annals of Statistics}, 29:1189\textendash{}1232, 2000.
\bibitem[Fri02]{zreferences:friedman2002}
Jerome H. Friedman. Stochastic gradient boosting. \sphinxstyleemphasis{Computational Statistics \& Data Analysis}, 38(4):367 \textendash{} 378, 2002. Nonlinear Methods and Data Mining. URL: \sphinxurl{http://www.sciencedirect.com/science/article/pii/S0167947301000652}, \sphinxhref{https://doi.org/https://doi.org/10.1016/S0167-9473(01)00065-2}{doi:https://doi.org/10.1016/S0167\sphinxhyphen{}9473(01)00065\sphinxhyphen{}2}.
\bibitem[HTF01]{zreferences:esl2001}
Trevor Hastie, Robert Tibshirani, and Jerome Friedman. \sphinxstyleemphasis{The Elements of Statistical Learning}. Springer Series in Statistics. Springer New York Inc., New York, NY, USA, 2001.
\bibitem[HTW15]{zreferences:slws2015}
Trevor Hastie, Robert Tibshirani, and Martin Wainwright. \sphinxstyleemphasis{Statistical Learning with Sparsity: The Lasso and Generalizations}. Chapman \& Hall/CRC, 2015. ISBN 1498712169.
\bibitem[KL95]{zreferences:kohavi1995}
Ron Kohavi and Chia\sphinxhyphen{}Hsin Li. Oblivious decision trees graphs and top down pruning. 1995.
\bibitem[KSH17]{zreferences:krizhevsky2017}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. \sphinxstyleemphasis{Commun. ACM}, 60(6):84\textendash{}90, May 2017. URL: \sphinxurl{https://doi.org/10.1145/3065386}, \sphinxhref{https://doi.org/10.1145/3065386}{doi:10.1145/3065386}.
\bibitem[LO17]{zreferences:yin2017}
Yin Lou and Mikhail Obukhov. Bdt: gradient boosted decision tables for high accuracy and scoring efficiency. 2017. URL: \sphinxurl{https://doi.org/10.1145/3097983.3098175}, \sphinxhref{https://doi.org/10.1145/3097983.3098175}{doi:10.1145/3097983.3098175}.
\bibitem[LKPM19]{zreferences:lu2019}
Haihao Lu, Sai Praneeth Karimireddy, Natalia Ponomareva, and Vahab Mirrokni. Accelerating gradient boosting machine. 2019. \sphinxhref{https://arxiv.org/abs/1903.08708}{arXiv:1903.08708}.
\bibitem[PMB19]{zreferences:popov2019}
Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles for deep learning on tabular data. 2019. \sphinxhref{https://arxiv.org/abs/1909.06312}{arXiv:1909.06312}.
\bibitem[PGV+17]{zreferences:prokhorenkova2017}
Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. Catboost: unbiased boosting with categorical features. 2017. \sphinxhref{https://arxiv.org/abs/1706.09516}{arXiv:1706.09516}.
\bibitem[SPH07]{zreferences:platt2007}
B. Schölkopf, J. Platt, and T. Hofmann. Adaboost is consistent. 2007.
\bibitem[SHK+14]{zreferences:srivastava2014}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. \sphinxstyleemphasis{J. Mach. Learn. Res.}, 15(1):1929\textendash{}1958, January 2014.
\bibitem[ZY05]{zreferences:yu2005}
Tong Zhang and Bin Yu. Boosting with early stopping: convergence and consistency. \sphinxstyleemphasis{The Annals of Statistics}, 33(4):1538\textendash{}1579, Aug 2005. URL: \sphinxurl{http://dx.doi.org/10.1214/009053605000000255}, \sphinxhref{https://doi.org/10.1214/009053605000000255}{doi:10.1214/009053605000000255}.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}